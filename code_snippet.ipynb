{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Navigate to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Mortality-Prediction-MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download dataset via kagglehub (Only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# path = kagglehub.dataset_download(\"mitishaagarwal/patient\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Give a variable to store the path\n",
    "- Read the CSV from the path\n",
    "- Display the first 5 rows of data to test if successfully read the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/soongjun/.cache/kagglehub/datasets/mitishaagarwal/patient/versions/3/dataset.csv\"\n",
    "# path = \"/root/.cache/kagglehub/datasets/mitishaagarwal/patient/versions/3/dataset.csv\"\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the number of rows and columns\n",
    "- Display the columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", data.shape, \"\\n\")\n",
    "print(\"Columns:\", data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop empty column by index\n",
    "- Count the number of rows and columns to ensure the column is removed\n",
    "- Display the new columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[-2], axis=1)\n",
    "data = data.drop(columns = [\"encounter_id\", \"hospital_id\"])\n",
    "\n",
    "print(\"Dataset shape:\", data.shape, \"\\n\")\n",
    "print(\"Columns:\", data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the total columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().mean() * 100\n",
    "\n",
    "missing_summary = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f\"Total columns with missing values: {missing_summary.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set a random seed to ensure the randomness is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate the columns into numerical and categorical\n",
    "- Handle missing values in numerical and categorical seperately\n",
    "- Numerical will fill in missing values with medium values\n",
    "- Categorical will fill in missing values with random choice from non-missing values\n",
    "- Check if missing values is remained exist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = data.select_dtypes(include=['number']).columns\n",
    "categorical_columns = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        non_missing_values = data[col].dropna().unique()\n",
    "        \n",
    "        data[col] = data[col].apply(\n",
    "            lambda x: np.random.choice(non_missing_values) if pd.isnull(x) else x\n",
    "        )\n",
    "\n",
    "missing_values_after_imputation = data.isnull().sum().sum()\n",
    "print(f\"Total missing values after imputation: {missing_values_after_imputation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the data types to identify categorical columns\n",
    "- Apply one-hot Encoding to to categorical columns\n",
    "- Count the number of rows and columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_columns, \"\\n\")\n",
    "# print(\"Data after one-hot encoding:\", \"\\n\")\n",
    "# print(df_encoded.head(), \"\\n\")\n",
    "print(\"Shape after encoding:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate the encoded data into X and y\n",
    "- Identify the numerical columns\n",
    "- Split the data into training, validation, and testing set\n",
    "- Data spliting ratio is 80:10:10\n",
    "- Apply SMOTE after splitting\n",
    "- Convert to numpy array in float data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['hospital_death', 'patient_id'])\n",
    "y = data['hospital_death']\n",
    "\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_indices = [X.columns.get_loc(col) for col in numerical_columns]\n",
    "\n",
    "# print(len(numerical_columns))\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train))\n",
    "\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "X_validate = np.array(X_validate, dtype=float)\n",
    "X_test = np.array(X_test, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply feature scaling after SMOTE\n",
    "- Display the shape of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[:, numerical_indices] = scaler.fit_transform(X_train[:, numerical_indices])\n",
    "X_validate[:, numerical_indices] = scaler.transform(X_validate[:, numerical_indices])\n",
    "X_test[:, numerical_indices] = scaler.transform(X_test[:, numerical_indices])\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_validate.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import external Python file which is the model architecture\n",
    "- Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_stopping import EarlyStopping\n",
    "from hyperparameter_utils import sample_hyperparameters, train_and_evaluate\n",
    "from model_utils import MLPModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if CUDA is available and set the device\n",
    "- Set initial hyperparameters\n",
    "- Call the model from external Python file\n",
    "- Display the architecture of the model\n",
    "- Apply Binary Cross Entropy Loss\n",
    "- Apply Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\", \"\\n\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_layers = [128, 64]\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "model = MLPModel(input_dim=input_dim, hidden_layers=hidden_layers, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert data into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate = y_validate.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert data into Tensor array\n",
    "- Assign variables for train and validate dataset\n",
    "- Feed the data into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_validate_tensor = torch.tensor(X_validate, dtype=torch.float32)\n",
    "y_validate_tensor = torch.tensor(y_validate, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_validate_tensor = X_validate_tensor.to(device)\n",
    "y_validate_tensor = y_validate_tensor.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "validate_dataset = TensorDataset(X_validate_tensor, y_validate_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validate_loader = DataLoader(validate_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate CUDA if available\n",
    "- List of hyperparameter prepared to tune\n",
    "- Set up number of trials to search the best hyperparameter\n",
    "- Apply early stopping during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'hidden_layers': [[128, 64], [256, 128], [64, 32]],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "num_trials = 9\n",
    "results = []\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    params = sample_hyperparameters(param_space)\n",
    "    validate_loss, params = train_and_evaluate(\n",
    "        params=params,\n",
    "        model_class=MLPModel,\n",
    "        input_dim=X_train.shape[1],\n",
    "        train_dataset=train_dataset,\n",
    "        validate_dataset=validate_dataset,\n",
    "        criterion=criterion,\n",
    "        num_epochs=100\n",
    "    )\n",
    "    results.append((validate_loss, params))\n",
    "\n",
    "results = sorted(results, key=lambda x: x[0])\n",
    "print(\"Best Configuration:\", results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the training data and validate data into one dataset\n",
    "- Extract the best hyperparameter tuning list\n",
    "- Train the model again with the best parameters\n",
    "- Apply early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = min(results, key=lambda x: x[0])\n",
    "best_params = best_result[1]\n",
    "\n",
    "X_train_combined = torch.cat((X_train_tensor, X_validate_tensor), dim=0).to(device)\n",
    "y_train_combined = torch.cat((y_train_tensor, y_validate_tensor), dim=0).to(device)\n",
    "\n",
    "combined_dataset = TensorDataset(X_train_combined, y_train_combined)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "\n",
    "model = MLPModel(\n",
    "    input_dim=X_train_combined.shape[1],\n",
    "    hidden_layers=best_params['hidden_layers'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=40, min_delta=0.0005)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "num_epochs = 400\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in combined_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(combined_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    early_stopping.check(train_loss)\n",
    "    if early_stopping.should_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualise the training loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the model's parameters instead of the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MLP_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert data into Tensor format\n",
    "- Load the model for testing phase\n",
    "- Use the saved model to evaluate the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "model = MLPModel(\n",
    "    input_dim=X_train_combined.shape[1],\n",
    "    hidden_layers=best_params['hidden_layers'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('MLP_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(test_predictions, y_test_tensor).item()\n",
    "\n",
    "    test_predictions = (test_predictions > 0.5).float()\n",
    "\n",
    "# print(f\"Test Loss: {test_loss:.4f}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Include metrics tracking and accuracy to assess the model's performance\n",
    "- Flatten the data into 1D array\n",
    "- Set a threshold prediction for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (test_predictions == y_test_tensor).sum().item()\n",
    "total_predictions = y_test_tensor.size(0)\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\", \"\\n\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\", \"\\n\")\n",
    "\n",
    "# y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "# y_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "y_test_np = y_test_tensor.numpy().flatten()\n",
    "y_pred_np = test_predictions.numpy().flatten()\n",
    "\n",
    "binary_predictions = (y_pred_np > 0.5).astype(int)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_np, y_pred_np), \"\\n\")\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test_np, y_pred_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test_np, binary_predictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot a precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test_np, y_pred_np)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot a ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_thresholds = roc_curve(y_test_np, y_pred_np)\n",
    "roc_auc = roc_auc_score(y_test_np, y_pred_np)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
